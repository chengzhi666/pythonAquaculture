# 虹鳟/帝王鲑采集与分析系统建设计划

## TL;DR
分四个阶段构建虹鳟/帝王鲑的线上线下价格监控与分析系统。第一阶段快速建立淘宝/京东商品采集 + 农业农村部线下价格源，扩展数据字典和规格解析规则；第二阶段完善CSV导入Excel方案；第三阶段实现价格时间序列预测；第四阶段顺序推进销量和产量预测。所有数据直接入MySQL，支持完整的溯源和去重。重点是通过词典+规则链而非NLP保证准确性。

---

## 实施步骤

### **第一阶段：线上销售数据采集系统（虹鳟/帝王鲑专供）**

#### **1.1 数据库结构扩展**

新增/修改 [fish_intel_mvp/schema.sql](fish_intel_mvp/schema.sql)：
   - 扩展 `product_snapshot` 表：增加品种、规格、产地、营养、认证等字段（共25+字段）
   - 新建 `product_type_dict` 表：虹鳟/帝王鲑过滤词典（regex匹配）
   - 新建 `spec_dict` 表：规格单位规范化词典
   - 新建 `origin_dict` 表：产地标准化映射（省市/国家）
   - 新建 `price_history_agg` 表：日/周/月级价格聚合表（用于趋势分析）

#### **1.2 数据解析引擎**

创建 [fish_intel_mvp/common/extract_rules.py](fish_intel_mvp/common/extract_rules.py)：
   - `ProductTypeExtractor` 类：用 `product_type_dict` 正则链匹配品种
   - `SpecExtractor` 类：规格解析链（重量+单位+数量分离）
   - `OriginExtractor` 类：产地标准化（省市/国家映射）
   - 所有规则从DB动态加载，支持热更新

#### **1.3 虹鳟专用爬虫**

创建 [fish_intel_mvp/jobs/crawl_salmon.py](fish_intel_mvp/jobs/crawl_salmon.py)：
   - `crawl_taobao_salmon()` / `crawl_jd_salmon()`：复用现有爬虫逻辑
   - 新增调用链：原始数据 → 品种识别 → 规格提取 → 产地标准化 → 价格追踪
   - 关键词配置（支持MySQL存储和环境变量覆盖）
   - 保留原始字段以便后续调试

#### **1.4 数据入库优化**

修改 [fish_intel_mvp/common/db.py](fish_intel_mvp/common/db.py)：
   - 扩展 `upsert_product_snapshot()` 函数支持新字段
   - 优化去重策略：`(platform, product_type, spec_weight_normalized, shop, snapshot_time)` 多维键
   - 添加 `calc_price_change()` 函数：计算N天内的价格变化百分比

#### **1.5 配置与任务编排**

更新 [config/sites.json](config/sites.json)：
   - 新增 `taobao_salmon` 和 `jd_salmon` 配置块
   - 关键词列表：虹鳟、帝王鲑、帝王三文鱼、rainbow、king salmon
   - 采集频率：每天固定时段（如08:00 / 20:00）

---

### **第二阶段：线下价格数据采集系统**

#### **2.1 农业农村部数据源集成**

创建 [fish_intel_mvp/jobs/crawl_moa_prices.py](fish_intel_mvp/jobs/crawl_moa_prices.py)：
   - 目标URL：农业农村部商务信息平台水产品价格监测数据页面
   - 采用 BeautifulSoup 解析表格或DrissionPage动态解析
   - 提取字段：日期、市场名称、品类、规格、价格、备注（冷冻/冰鲜等）

#### **2.2 线下价格数据库表**

新建表 [fish_intel_mvp/schema.sql](fish_intel_mvp/schema.sql) 中的 `offline_price_snapshot`：
   ```sql
   offline_price_snapshot (
     id, source_name, market_name, region, product_type,
     spec, price, unit, storage_method, snapshot_time,
     raw_id FK raw_event.id
   )
   ```
   - 同样保留 `raw_id` 用于数据溯源
   - 按 `(source_name, market_name, product_type, snapshot_time)` 建去重唯一键

#### **2.3 数据导入脚本**

创建 [fish_intel_mvp/jobs/import_offline_prices.py](fish_intel_mvp/jobs/import_offline_prices.py)：
   - 以CSV为中间格式（便于手动检查和交付）
   - 支持从 `price_offline_*.csv` 批量导入到 `offline_price_snapshot` 表
   - 字段映射和数据校验逻辑

---

### **第三阶段：官方统计数据导入系统**

#### **3.1 Excel模板与导入脚本**

创建 [fish_intel_mvp/templates/production_data_template.xlsx](fish_intel_mvp/templates/production_data_template.xlsx)：
   - 列定义：年份、产地/国家、品类、数值、数据类型、来源说明、口径说明

创建 [fish_intel_mvp/jobs/import_production_data.py](fish_intel_mvp/jobs/import_production_data.py)：
   - 读取Excel，校验字段和数据类型
   - 数据标准化：产地识别、数据类型分类

#### **3.2 统计数据库表**

新建表 [fish_intel_mvp/schema.sql](fish_intel_mvp/schema.sql) 中的 `production_data`：
   ```sql
   production_data (
     id, year, origin_region, product_type, value,
     data_type, source_note, cal_note, imported_at
   )
   ```

---

### **第四阶段：数据分析与预测系统**

#### **4.1 数据对齐与聚合**

创建 [fish_intel_mvp/analysis/data_integration.py](fish_intel_mvp/analysis/data_integration.py)：
   - 按日期、品类、规格对齐三类数据（线上、线下、统计）
   - 聚合函数：按周/月计算均价、销量均值、库存推算

#### **4.2 趋势分析模块**

创建 [fish_intel_mvp/analysis/trend_analysis.py](fish_intel_mvp/analysis/trend_analysis.py)：
   - 绘制价格走势图（日/周/月粒度）
   - 销量趋势对标
   - 跨数据源关联分析（供应量与规格 → 价格变化）

#### **4.3 预测模型**（按优先级实现）

**Priority 1: 价格预测** [fish_intel_mvp/analysis/forecast_price.py](fish_intel_mvp/analysis/forecast_price.py)
   - 基础方法：移动平均（MA7/MA30）+ 季节分解（ARIMA或Prophet）
   - 输出：未来1-3个月的周均价预测+置信区间

**Priority 2: 销量预测** [fish_intel_mvp/analysis/forecast_sales.py](fish_intel_mvp/analysis/forecast_sales.py)
   - 按平台/店铺维度聚合销量趋势
   - 使用与价格预测相同的时间序列方法

**Priority 3: 产量预测** [fish_intel_mvp/analysis/forecast_production.py](fish_intel_mvp/analysis/forecast_production.py)
   - 基于历年官方统计数据推算趋势
   - 考虑产地间的替代关系

#### **4.4 报告生成**

创建 [fish_intel_mvp/analysis/report_generator.py](fish_intel_mvp/analysis/report_generator.py)：
   - 使用 plotly / matplotlib 生成交互式图表
   - 导出为PDF或HTML报告（标注影响因子和数据来源）
   - Streamlit集成：新增"分析报告"页面

---

### **第五阶段：质量与运维**

#### **5.1 数据质量检查**

创建 [fish_intel_mvp/common/data_validation.py](fish_intel_mvp/common/data_validation.py)：
   - 规则词典覆盖率检测（有多少百分比的商品被成功识别为虹鳟/帝王鲑）
   - 价格异常值检测（Z-score方法）
   - 缺失字段监控

#### **5.2 字典和规则维护**

创建 [fish_intel_mvp/admin/dict_manager.py](fish_intel_mvp/admin/dict_manager.py)：
   - 简单的管理页面或CLI，支持增删改规则词汇
   - 规则预测试功能（输入商品标题，显示识别结果）
   - 历史变更审计

#### **5.3 日志和告警**

修改 [fish_intel_mvp/common/logger.py](fish_intel_mvp/common/logger.py)：
   - 记录规则命中率、采集失败率
   - 定期生成数据质量报告

---

## 验证计划

1. **数据采集验证**
   - 运行 `python -m pytest tests/test_extract_rules.py`：验证品种+规格提取准确率 ≥ 95%
   - 手动抽查 50 条采集数据，确保字段完整性
   - 对比Taobao/JD官网，检查去重是否有遗漏

2. **线下数据验证**
   - 对比农业农村部官网最新数据，确保采集延迟 < 2小时
   - 验证导入脚本能正确处理缺失值和异常格式

3. **统计数据导入验证**
   - 测试Excel模板导入：输入5条样本数据，验证入库正确性
   - 检查数据溯源：查看 `raw_event` 是否记录了Excel导入的元数据

4. **分析和预测验证**
   - 对历史数据进行回测：预测值与实际值的偏离度 < 15%
   - 生成样本报告，评估可读性和决策指导作用

5. **集成测试**
   - 运行完整流程：采集 → 入库 → 聚合 → 预测 → 报告
   - 验证Streamlit界面能正确展示所有功能

---

## 决策点

- **词典+规则 vs NLP**：选择前者保证可解释性和快速迭代，后续只在精度不足时考虑引入NLP
- **MySQL存储**：放弃CSV中间态，直接入库，提升数据实时性和查询效率
- **多维去重**：从简单的URL去重升级到 `(平台, 品种, 规格, 店铺, 时间)` 多维去重，避免重复计数
- **数据溯源**：所有数据源保留 `raw_event` 链接，支持完整审计和错误回溯
- **采集源扩展**：第一阶段稳定后，可轻松扩展到其他电商平台或线下渠道（通过配置 + 词典）
- **分析维度顺序**：按难度递增预测价格 → 销量 → 产量，确保MVP快速见成效
